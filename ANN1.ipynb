{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "lP6JLo1tGNBg"
   },
   "source": [
    "# Deriving an ANN for predicting customer churn:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "gWZyYmS_UE_L"
   },
   "source": [
    "### Importing the libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "MxkJoQBkUIHC"
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import tensorflow as tf"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "1E0Q3aoKUCRX"
   },
   "source": [
    "## Part 1 - Data Preprocessing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "cKWAkFVGUU0Z"
   },
   "source": [
    "### Importing the dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "MXUkhkMfU4wq"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>RowNumber</th>\n",
       "      <th>CustomerId</th>\n",
       "      <th>Surname</th>\n",
       "      <th>CreditScore</th>\n",
       "      <th>Geography</th>\n",
       "      <th>Gender</th>\n",
       "      <th>Age</th>\n",
       "      <th>Tenure</th>\n",
       "      <th>Balance</th>\n",
       "      <th>NumOfProducts</th>\n",
       "      <th>HasCrCard</th>\n",
       "      <th>IsActiveMember</th>\n",
       "      <th>EstimatedSalary</th>\n",
       "      <th>Exited</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>15634602</td>\n",
       "      <td>Hargrave</td>\n",
       "      <td>619</td>\n",
       "      <td>France</td>\n",
       "      <td>Female</td>\n",
       "      <td>42</td>\n",
       "      <td>2</td>\n",
       "      <td>0.00</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>101348.88</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>15647311</td>\n",
       "      <td>Hill</td>\n",
       "      <td>608</td>\n",
       "      <td>Spain</td>\n",
       "      <td>Female</td>\n",
       "      <td>41</td>\n",
       "      <td>1</td>\n",
       "      <td>83807.86</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>112542.58</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>15619304</td>\n",
       "      <td>Onio</td>\n",
       "      <td>502</td>\n",
       "      <td>France</td>\n",
       "      <td>Female</td>\n",
       "      <td>42</td>\n",
       "      <td>8</td>\n",
       "      <td>159660.80</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>113931.57</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>15701354</td>\n",
       "      <td>Boni</td>\n",
       "      <td>699</td>\n",
       "      <td>France</td>\n",
       "      <td>Female</td>\n",
       "      <td>39</td>\n",
       "      <td>1</td>\n",
       "      <td>0.00</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>93826.63</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>15737888</td>\n",
       "      <td>Mitchell</td>\n",
       "      <td>850</td>\n",
       "      <td>Spain</td>\n",
       "      <td>Female</td>\n",
       "      <td>43</td>\n",
       "      <td>2</td>\n",
       "      <td>125510.82</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>79084.10</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   RowNumber  CustomerId   Surname  CreditScore Geography  Gender  Age  \\\n",
       "0          1    15634602  Hargrave          619    France  Female   42   \n",
       "1          2    15647311      Hill          608     Spain  Female   41   \n",
       "2          3    15619304      Onio          502    France  Female   42   \n",
       "3          4    15701354      Boni          699    France  Female   39   \n",
       "4          5    15737888  Mitchell          850     Spain  Female   43   \n",
       "\n",
       "   Tenure    Balance  NumOfProducts  HasCrCard  IsActiveMember  \\\n",
       "0       2       0.00              1          1               1   \n",
       "1       1   83807.86              1          0               1   \n",
       "2       8  159660.80              3          1               0   \n",
       "3       1       0.00              2          0               0   \n",
       "4       2  125510.82              1          1               1   \n",
       "\n",
       "   EstimatedSalary  Exited  \n",
       "0        101348.88       1  \n",
       "1        112542.58       0  \n",
       "2        113931.57       1  \n",
       "3         93826.63       0  \n",
       "4         79084.10       0  "
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset = pd.read_csv('Churn_Modelling.csv')\n",
    "dataset.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 10000 entries, 0 to 9999\n",
      "Data columns (total 14 columns):\n",
      " #   Column           Non-Null Count  Dtype  \n",
      "---  ------           --------------  -----  \n",
      " 0   RowNumber        10000 non-null  int64  \n",
      " 1   CustomerId       10000 non-null  int64  \n",
      " 2   Surname          10000 non-null  object \n",
      " 3   CreditScore      10000 non-null  int64  \n",
      " 4   Geography        10000 non-null  object \n",
      " 5   Gender           10000 non-null  object \n",
      " 6   Age              10000 non-null  int64  \n",
      " 7   Tenure           10000 non-null  int64  \n",
      " 8   Balance          10000 non-null  float64\n",
      " 9   NumOfProducts    10000 non-null  int64  \n",
      " 10  HasCrCard        10000 non-null  int64  \n",
      " 11  IsActiveMember   10000 non-null  int64  \n",
      " 12  EstimatedSalary  10000 non-null  float64\n",
      " 13  Exited           10000 non-null  int64  \n",
      "dtypes: float64(2), int64(9), object(3)\n",
      "memory usage: 1.1+ MB\n"
     ]
    }
   ],
   "source": [
    "dataset.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>RowNumber</th>\n",
       "      <th>CustomerId</th>\n",
       "      <th>CreditScore</th>\n",
       "      <th>Age</th>\n",
       "      <th>Tenure</th>\n",
       "      <th>Balance</th>\n",
       "      <th>NumOfProducts</th>\n",
       "      <th>HasCrCard</th>\n",
       "      <th>IsActiveMember</th>\n",
       "      <th>EstimatedSalary</th>\n",
       "      <th>Exited</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>10000.00000</td>\n",
       "      <td>1.000000e+04</td>\n",
       "      <td>10000.000000</td>\n",
       "      <td>10000.000000</td>\n",
       "      <td>10000.000000</td>\n",
       "      <td>10000.000000</td>\n",
       "      <td>10000.000000</td>\n",
       "      <td>10000.00000</td>\n",
       "      <td>10000.000000</td>\n",
       "      <td>10000.000000</td>\n",
       "      <td>10000.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>5000.50000</td>\n",
       "      <td>1.569094e+07</td>\n",
       "      <td>650.528800</td>\n",
       "      <td>38.921800</td>\n",
       "      <td>5.012800</td>\n",
       "      <td>76485.889288</td>\n",
       "      <td>1.530200</td>\n",
       "      <td>0.70550</td>\n",
       "      <td>0.515100</td>\n",
       "      <td>100090.239881</td>\n",
       "      <td>0.203700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>2886.89568</td>\n",
       "      <td>7.193619e+04</td>\n",
       "      <td>96.653299</td>\n",
       "      <td>10.487806</td>\n",
       "      <td>2.892174</td>\n",
       "      <td>62397.405202</td>\n",
       "      <td>0.581654</td>\n",
       "      <td>0.45584</td>\n",
       "      <td>0.499797</td>\n",
       "      <td>57510.492818</td>\n",
       "      <td>0.402769</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>1.00000</td>\n",
       "      <td>1.556570e+07</td>\n",
       "      <td>350.000000</td>\n",
       "      <td>18.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>11.580000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>2500.75000</td>\n",
       "      <td>1.562853e+07</td>\n",
       "      <td>584.000000</td>\n",
       "      <td>32.000000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>51002.110000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>5000.50000</td>\n",
       "      <td>1.569074e+07</td>\n",
       "      <td>652.000000</td>\n",
       "      <td>37.000000</td>\n",
       "      <td>5.000000</td>\n",
       "      <td>97198.540000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.00000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>100193.915000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>7500.25000</td>\n",
       "      <td>1.575323e+07</td>\n",
       "      <td>718.000000</td>\n",
       "      <td>44.000000</td>\n",
       "      <td>7.000000</td>\n",
       "      <td>127644.240000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>1.00000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>149388.247500</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>10000.00000</td>\n",
       "      <td>1.581569e+07</td>\n",
       "      <td>850.000000</td>\n",
       "      <td>92.000000</td>\n",
       "      <td>10.000000</td>\n",
       "      <td>250898.090000</td>\n",
       "      <td>4.000000</td>\n",
       "      <td>1.00000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>199992.480000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         RowNumber    CustomerId   CreditScore           Age        Tenure  \\\n",
       "count  10000.00000  1.000000e+04  10000.000000  10000.000000  10000.000000   \n",
       "mean    5000.50000  1.569094e+07    650.528800     38.921800      5.012800   \n",
       "std     2886.89568  7.193619e+04     96.653299     10.487806      2.892174   \n",
       "min        1.00000  1.556570e+07    350.000000     18.000000      0.000000   \n",
       "25%     2500.75000  1.562853e+07    584.000000     32.000000      3.000000   \n",
       "50%     5000.50000  1.569074e+07    652.000000     37.000000      5.000000   \n",
       "75%     7500.25000  1.575323e+07    718.000000     44.000000      7.000000   \n",
       "max    10000.00000  1.581569e+07    850.000000     92.000000     10.000000   \n",
       "\n",
       "             Balance  NumOfProducts    HasCrCard  IsActiveMember  \\\n",
       "count   10000.000000   10000.000000  10000.00000    10000.000000   \n",
       "mean    76485.889288       1.530200      0.70550        0.515100   \n",
       "std     62397.405202       0.581654      0.45584        0.499797   \n",
       "min         0.000000       1.000000      0.00000        0.000000   \n",
       "25%         0.000000       1.000000      0.00000        0.000000   \n",
       "50%     97198.540000       1.000000      1.00000        1.000000   \n",
       "75%    127644.240000       2.000000      1.00000        1.000000   \n",
       "max    250898.090000       4.000000      1.00000        1.000000   \n",
       "\n",
       "       EstimatedSalary        Exited  \n",
       "count     10000.000000  10000.000000  \n",
       "mean     100090.239881      0.203700  \n",
       "std       57510.492818      0.402769  \n",
       "min          11.580000      0.000000  \n",
       "25%       51002.110000      0.000000  \n",
       "50%      100193.915000      0.000000  \n",
       "75%      149388.247500      0.000000  \n",
       "max      199992.480000      1.000000  "
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "RowNumber          0\n",
       "CustomerId         0\n",
       "Surname            0\n",
       "CreditScore        0\n",
       "Geography          0\n",
       "Gender             0\n",
       "Age                0\n",
       "Tenure             0\n",
       "Balance            0\n",
       "NumOfProducts      0\n",
       "HasCrCard          0\n",
       "IsActiveMember     0\n",
       "EstimatedSalary    0\n",
       "Exited             0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#let us make sure that there are no missing values\n",
    "dataset.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "#lets define the predictors and the predicted values: We will not be using the intital 3 columns for our analysis as they are not relevant.\n",
    "X = dataset.iloc[:, 3:-1].values   #  .values ignores the labels and just stores the associated values \n",
    "y = dataset.iloc[:, -1].values   #this is the predicted value (Dependent Variable)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 137
    },
    "colab_type": "code",
    "id": "VYP9cQTWbzuI",
    "outputId": "797e7a64-9bac-436a-8c9c-94437e5e7587"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[619 'France' 'Female' ... 1 1 101348.88]\n",
      " [608 'Spain' 'Female' ... 0 1 112542.58]\n",
      " [502 'France' 'Female' ... 1 0 113931.57]\n",
      " ...\n",
      " [709 'France' 'Female' ... 0 1 42085.58]\n",
      " [772 'Germany' 'Male' ... 1 0 92888.52]\n",
      " [792 'France' 'Female' ... 1 0 38190.78]]\n"
     ]
    }
   ],
   "source": [
    "print(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "38vKGE6Nb2RR",
    "outputId": "a815e42a-e0dd-4cb5-ab97-b17ead98fbc3"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1 0 1 ... 1 1 0]\n"
     ]
    }
   ],
   "source": [
    "print(y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "N6bQ0UgSU-NJ"
   },
   "source": [
    "### Encoding categorical data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "LabelEncoder can turn [dog,cat,dog,mouse,cat] into [1,2,1,3,2], but then the imposed ordinality means that the average of dog and mouse is cat. Still there are algorithms like decision trees and random forests that can work with categorical variables just fine and LabelEncoder can be used to store values using less disk space.\n",
    "\n",
    "One-Hot-Encoding has the advantage that the result is binary rather than ordinal and that everything sits in an orthogonal vector space. The disadvantage is that for high cardinality, the feature space can really blow up quickly and you start fighting with the curse of dimensionality. In these cases, I typically employ one-hot-encoding followed by PCA for dimensionality reduction. I find that the judicious combination of one-hot plus PCA can seldom be beat by other encoding schemes. PCA finds the linear overlap, so will naturally tend to group similar features into the same feature."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "le5MJreAbW52"
   },
   "source": [
    "**Label Encoding the \"Gender\" column**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "PxVKWXxLbczC"
   },
   "outputs": [],
   "source": [
    "#we are using label encoding to encode the labels (Predicted values) of our dataset\n",
    "\n",
    "from sklearn.preprocessing import LabelEncoder #we are using this as it has just 2 categories\n",
    "le = LabelEncoder()  #Lets create an object for the label encoder so we can access it.\n",
    "X[:, 2] = le.fit_transform(X[:, 2])  #Label encoder has the fit_transform function."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 137
    },
    "colab_type": "code",
    "id": "-M1KboxFb6OO",
    "outputId": "e2b8c7e8-0cbc-4cdf-f4eb-7f0853a00b88"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[619 'France' 0 ... 1 1 101348.88]\n",
      " [608 'Spain' 0 ... 0 1 112542.58]\n",
      " [502 'France' 0 ... 1 0 113931.57]\n",
      " ...\n",
      " [709 'France' 0 ... 0 1 42085.58]\n",
      " [772 'Germany' 1 ... 1 0 92888.52]\n",
      " [792 'France' 0 ... 1 0 38190.78]]\n"
     ]
    }
   ],
   "source": [
    "print(X)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "CUxGZezpbMcb"
   },
   "source": [
    "**One Hot Encoding the \"Geography\" column**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "AMXC8-KMVirw"
   },
   "outputs": [],
   "source": [
    "#lets \n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "ct = ColumnTransformer(transformers=[('encoder', OneHotEncoder(), [1])], remainder='passthrough') #passthrough ensures that the other columns are passed through untransformed \n",
    "X = np.array(ct.fit_transform(X))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 137
    },
    "colab_type": "code",
    "id": "ZcxwEon-b8nV",
    "outputId": "23a98af4-5e33-4b26-c27b-f06e3c5d2baf"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[1.0 0.0 0.0 ... 1 1 101348.88]\n",
      " [0.0 0.0 1.0 ... 0 1 112542.58]\n",
      " [1.0 0.0 0.0 ... 1 0 113931.57]\n",
      " ...\n",
      " [1.0 0.0 0.0 ... 0 1 42085.58]\n",
      " [0.0 1.0 0.0 ... 1 0 92888.52]\n",
      " [1.0 0.0 0.0 ... 1 0 38190.78]]\n"
     ]
    }
   ],
   "source": [
    "print(X)\n",
    "#one-hot encoding shifts the newly created features to the left of the dataset."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "vHol938cW8zd"
   },
   "source": [
    "### Splitting the dataset into the Training set and Test set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "Z-TDt0Y_XEfc"
   },
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.3, random_state = 42)#30% data has been used for testing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "RE_FcHyfV3TQ"
   },
   "source": [
    "### Feature Scaling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "ViCrE00rV8Sk"
   },
   "outputs": [],
   "source": [
    "#Note that all the features need to be scaled for making an effective Neural network\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "sc = StandardScaler()\n",
    "X_train = sc.fit_transform(X_train)\n",
    "X_test = sc.transform(X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "-zfEzkRVXIwF"
   },
   "source": [
    "## Part 2 - Building the ANN"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "KvdeScabXtlB"
   },
   "source": [
    "### Initializing the ANN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "3dtrScHxXQox"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Sequential specifies to keras that we are creating model sequentially and the output of each\\nlayer we add is input to the next layer we specify.'"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#lets create an object ann.\n",
    "ann = tf.keras.models.Sequential()  #since keras 2.0 it has been integrated into TensorFlow\n",
    "\n",
    "'''Sequential specifies to keras that we are creating model sequentially and the output of each\n",
    "layer we add is input to the next layer we specify.'''"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "rP6urV6SX7kS"
   },
   "source": [
    "### Adding the input layer and the first hidden layer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "bppGycBXYCQr"
   },
   "outputs": [],
   "source": [
    "ann.add(tf.keras.layers.Dense(units=6, activation='relu'))  #rectified linear unit, it is the most frequently used."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "BELWAc_8YJze"
   },
   "source": [
    "### Adding the second hidden layer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "JneR0u0sYRTd"
   },
   "outputs": [],
   "source": [
    "ann.add(tf.keras.layers.Dense(units=6, activation='relu')) #the code is entirely the same, you can change the hyperparameters here to increaset the accuracy"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "OyNEe6RXYcU4"
   },
   "source": [
    "### Adding the output layer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "Cn3x41RBYfvY"
   },
   "outputs": [],
   "source": [
    "ann.add(tf.keras.layers.Dense(units=1, activation='sigmoid'))\n",
    "#softmax must be used for the non-binary outputs here."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "JT4u2S1_Y4WG"
   },
   "source": [
    "## Part 3 - Training the ANN"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "8GWlJChhY_ZI"
   },
   "source": [
    "### Compiling the ANN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "fG3RrwDXZEaS"
   },
   "outputs": [],
   "source": [
    "ann.compile(optimizer = 'adam', loss = 'binary_crossentropy', metrics = ['accuracy'])\n",
    "#optimizer=adam allows for stochastic gradient descent.  \n",
    "#for categorical output  we would use categorical entropy.\n",
    "#accuarcy accepts an array of multiple metrics and hence uses a square parenthesis."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "0QR_G5u7ZLSM"
   },
   "source": [
    "### Training the ANN on the Training set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "colab_type": "code",
    "id": "nHZ-LKv_ZRb3",
    "outputId": "718cc4b0-b5aa-40f0-9b20-d3d31730a531"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "219/219 [==============================] - 0s 788us/step - loss: 0.5945 - accuracy: 0.7081\n",
      "Epoch 2/100\n",
      "219/219 [==============================] - 0s 833us/step - loss: 0.4826 - accuracy: 0.7920\n",
      "Epoch 3/100\n",
      "219/219 [==============================] - 0s 806us/step - loss: 0.4601 - accuracy: 0.7929\n",
      "Epoch 4/100\n",
      "219/219 [==============================] - 0s 1ms/step - loss: 0.4492 - accuracy: 0.7941\n",
      "Epoch 5/100\n",
      "219/219 [==============================] - 0s 958us/step - loss: 0.4422 - accuracy: 0.7953\n",
      "Epoch 6/100\n",
      "219/219 [==============================] - 0s 888us/step - loss: 0.4371 - accuracy: 0.7986\n",
      "Epoch 7/100\n",
      "219/219 [==============================] - 0s 879us/step - loss: 0.4328 - accuracy: 0.8003\n",
      "Epoch 8/100\n",
      "219/219 [==============================] - 0s 906us/step - loss: 0.4285 - accuracy: 0.8041\n",
      "Epoch 9/100\n",
      "219/219 [==============================] - 0s 1ms/step - loss: 0.4239 - accuracy: 0.8101\n",
      "Epoch 10/100\n",
      "219/219 [==============================] - 0s 802us/step - loss: 0.4183 - accuracy: 0.8177\n",
      "Epoch 11/100\n",
      "219/219 [==============================] - 0s 710us/step - loss: 0.4125 - accuracy: 0.8241\n",
      "Epoch 12/100\n",
      "219/219 [==============================] - 0s 741us/step - loss: 0.4056 - accuracy: 0.8257\n",
      "Epoch 13/100\n",
      "219/219 [==============================] - 0s 802us/step - loss: 0.3989 - accuracy: 0.8287\n",
      "Epoch 14/100\n",
      "219/219 [==============================] - 0s 771us/step - loss: 0.3910 - accuracy: 0.8316\n",
      "Epoch 15/100\n",
      "219/219 [==============================] - 0s 806us/step - loss: 0.3834 - accuracy: 0.8343\n",
      "Epoch 16/100\n",
      "219/219 [==============================] - 0s 802us/step - loss: 0.3755 - accuracy: 0.8387\n",
      "Epoch 17/100\n",
      "219/219 [==============================] - 0s 751us/step - loss: 0.3689 - accuracy: 0.8439\n",
      "Epoch 18/100\n",
      "219/219 [==============================] - 0s 774us/step - loss: 0.3637 - accuracy: 0.8470\n",
      "Epoch 19/100\n",
      "219/219 [==============================] - ETA: 0s - loss: 0.3573 - accuracy: 0.85 - 0s 787us/step - loss: 0.3592 - accuracy: 0.8499\n",
      "Epoch 20/100\n",
      "219/219 [==============================] - 0s 1ms/step - loss: 0.3560 - accuracy: 0.8544\n",
      "Epoch 21/100\n",
      "219/219 [==============================] - 0s 2ms/step - loss: 0.3538 - accuracy: 0.8539\n",
      "Epoch 22/100\n",
      "219/219 [==============================] - 0s 2ms/step - loss: 0.3519 - accuracy: 0.8541\n",
      "Epoch 23/100\n",
      "219/219 [==============================] - 0s 1ms/step - loss: 0.3509 - accuracy: 0.8544\n",
      "Epoch 24/100\n",
      "219/219 [==============================] - 0s 783us/step - loss: 0.3497 - accuracy: 0.8554\n",
      "Epoch 25/100\n",
      "219/219 [==============================] - 0s 720us/step - loss: 0.3493 - accuracy: 0.8546\n",
      "Epoch 26/100\n",
      "219/219 [==============================] - 0s 765us/step - loss: 0.3480 - accuracy: 0.8569\n",
      "Epoch 27/100\n",
      "219/219 [==============================] - 0s 785us/step - loss: 0.3473 - accuracy: 0.8574\n",
      "Epoch 28/100\n",
      "219/219 [==============================] - 0s 781us/step - loss: 0.3468 - accuracy: 0.8549\n",
      "Epoch 29/100\n",
      "219/219 [==============================] - 0s 865us/step - loss: 0.3468 - accuracy: 0.8557\n",
      "Epoch 30/100\n",
      "219/219 [==============================] - 0s 792us/step - loss: 0.3464 - accuracy: 0.8569\n",
      "Epoch 31/100\n",
      "219/219 [==============================] - 0s 797us/step - loss: 0.3459 - accuracy: 0.8583\n",
      "Epoch 32/100\n",
      "219/219 [==============================] - 0s 893us/step - loss: 0.3455 - accuracy: 0.8567\n",
      "Epoch 33/100\n",
      "219/219 [==============================] - 0s 733us/step - loss: 0.3452 - accuracy: 0.8567\n",
      "Epoch 34/100\n",
      "219/219 [==============================] - 0s 791us/step - loss: 0.3448 - accuracy: 0.8581\n",
      "Epoch 35/100\n",
      "219/219 [==============================] - 0s 1ms/step - loss: 0.3444 - accuracy: 0.8567\n",
      "Epoch 36/100\n",
      "219/219 [==============================] - 0s 2ms/step - loss: 0.3442 - accuracy: 0.8589\n",
      "Epoch 37/100\n",
      "219/219 [==============================] - 0s 1ms/step - loss: 0.3436 - accuracy: 0.8577\n",
      "Epoch 38/100\n",
      "219/219 [==============================] - 0s 1ms/step - loss: 0.3442 - accuracy: 0.8577\n",
      "Epoch 39/100\n",
      "219/219 [==============================] - 0s 2ms/step - loss: 0.3439 - accuracy: 0.8579\n",
      "Epoch 40/100\n",
      "219/219 [==============================] - 0s 2ms/step - loss: 0.3438 - accuracy: 0.8594\n",
      "Epoch 41/100\n",
      "219/219 [==============================] - 1s 3ms/step - loss: 0.3435 - accuracy: 0.8577\n",
      "Epoch 42/100\n",
      "219/219 [==============================] - 1s 3ms/step - loss: 0.3431 - accuracy: 0.8591\n",
      "Epoch 43/100\n",
      "219/219 [==============================] - 0s 2ms/step - loss: 0.3431 - accuracy: 0.8583\n",
      "Epoch 44/100\n",
      "219/219 [==============================] - 0s 879us/step - loss: 0.3432 - accuracy: 0.8593\n",
      "Epoch 45/100\n",
      "219/219 [==============================] - 0s 1ms/step - loss: 0.3428 - accuracy: 0.8576\n",
      "Epoch 46/100\n",
      "219/219 [==============================] - 0s 924us/step - loss: 0.3430 - accuracy: 0.8591\n",
      "Epoch 47/100\n",
      "219/219 [==============================] - 0s 943us/step - loss: 0.3426 - accuracy: 0.8597\n",
      "Epoch 48/100\n",
      "219/219 [==============================] - 0s 1ms/step - loss: 0.3424 - accuracy: 0.8597\n",
      "Epoch 49/100\n",
      "219/219 [==============================] - 0s 1ms/step - loss: 0.3425 - accuracy: 0.8594\n",
      "Epoch 50/100\n",
      "219/219 [==============================] - 0s 1ms/step - loss: 0.3421 - accuracy: 0.8594\n",
      "Epoch 51/100\n",
      "219/219 [==============================] - 1s 3ms/step - loss: 0.3415 - accuracy: 0.8589\n",
      "Epoch 52/100\n",
      "219/219 [==============================] - 0s 2ms/step - loss: 0.3414 - accuracy: 0.8587\n",
      "Epoch 53/100\n",
      "219/219 [==============================] - 0s 979us/step - loss: 0.3417 - accuracy: 0.8594\n",
      "Epoch 54/100\n",
      "219/219 [==============================] - 0s 1ms/step - loss: 0.3413 - accuracy: 0.8590\n",
      "Epoch 55/100\n",
      "219/219 [==============================] - 0s 1ms/step - loss: 0.3410 - accuracy: 0.8591\n",
      "Epoch 56/100\n",
      "219/219 [==============================] - 0s 1ms/step - loss: 0.3409 - accuracy: 0.8597\n",
      "Epoch 57/100\n",
      "219/219 [==============================] - 0s 1ms/step - loss: 0.3409 - accuracy: 0.8590\n",
      "Epoch 58/100\n",
      "219/219 [==============================] - 0s 1ms/step - loss: 0.3409 - accuracy: 0.8583\n",
      "Epoch 59/100\n",
      "219/219 [==============================] - 0s 1ms/step - loss: 0.3403 - accuracy: 0.8590\n",
      "Epoch 60/100\n",
      "219/219 [==============================] - 0s 936us/step - loss: 0.3408 - accuracy: 0.8597\n",
      "Epoch 61/100\n",
      "219/219 [==============================] - 0s 1ms/step - loss: 0.3403 - accuracy: 0.8587\n",
      "Epoch 62/100\n",
      "219/219 [==============================] - 0s 852us/step - loss: 0.3397 - accuracy: 0.8599\n",
      "Epoch 63/100\n",
      "219/219 [==============================] - 0s 1ms/step - loss: 0.3398 - accuracy: 0.8581\n",
      "Epoch 64/100\n",
      "219/219 [==============================] - 0s 1ms/step - loss: 0.3398 - accuracy: 0.8596\n",
      "Epoch 65/100\n",
      "219/219 [==============================] - 0s 956us/step - loss: 0.3393 - accuracy: 0.8584\n",
      "Epoch 66/100\n",
      "219/219 [==============================] - 0s 915us/step - loss: 0.3391 - accuracy: 0.8580\n",
      "Epoch 67/100\n",
      "219/219 [==============================] - 0s 759us/step - loss: 0.3391 - accuracy: 0.8581\n",
      "Epoch 68/100\n",
      "219/219 [==============================] - 0s 747us/step - loss: 0.3397 - accuracy: 0.8576\n",
      "Epoch 69/100\n",
      "219/219 [==============================] - 0s 742us/step - loss: 0.3390 - accuracy: 0.8589\n",
      "Epoch 70/100\n",
      "219/219 [==============================] - 0s 1ms/step - loss: 0.3385 - accuracy: 0.8597\n",
      "Epoch 71/100\n",
      "219/219 [==============================] - 0s 2ms/step - loss: 0.3388 - accuracy: 0.8590\n",
      "Epoch 72/100\n",
      "219/219 [==============================] - 0s 2ms/step - loss: 0.3386 - accuracy: 0.8597\n",
      "Epoch 73/100\n",
      "219/219 [==============================] - 0s 1ms/step - loss: 0.3383 - accuracy: 0.8581\n",
      "Epoch 74/100\n",
      "219/219 [==============================] - 0s 1ms/step - loss: 0.3381 - accuracy: 0.8581\n",
      "Epoch 75/100\n",
      "219/219 [==============================] - 0s 645us/step - loss: 0.3381 - accuracy: 0.8587\n",
      "Epoch 76/100\n",
      "219/219 [==============================] - 0s 634us/step - loss: 0.3381 - accuracy: 0.8616\n",
      "Epoch 77/100\n",
      "219/219 [==============================] - 0s 774us/step - loss: 0.3379 - accuracy: 0.8591\n",
      "Epoch 78/100\n",
      "219/219 [==============================] - 0s 720us/step - loss: 0.3377 - accuracy: 0.8593\n",
      "Epoch 79/100\n",
      "219/219 [==============================] - 0s 690us/step - loss: 0.3379 - accuracy: 0.8590\n",
      "Epoch 80/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "219/219 [==============================] - 0s 788us/step - loss: 0.3376 - accuracy: 0.8600\n",
      "Epoch 81/100\n",
      "219/219 [==============================] - 0s 765us/step - loss: 0.3373 - accuracy: 0.8579\n",
      "Epoch 82/100\n",
      "219/219 [==============================] - 0s 729us/step - loss: 0.3372 - accuracy: 0.8577\n",
      "Epoch 83/100\n",
      "219/219 [==============================] - 0s 820us/step - loss: 0.3373 - accuracy: 0.8591\n",
      "Epoch 84/100\n",
      "219/219 [==============================] - 0s 865us/step - loss: 0.3368 - accuracy: 0.8604\n",
      "Epoch 85/100\n",
      "219/219 [==============================] - 0s 916us/step - loss: 0.3372 - accuracy: 0.8591\n",
      "Epoch 86/100\n",
      "219/219 [==============================] - 0s 888us/step - loss: 0.3375 - accuracy: 0.8581\n",
      "Epoch 87/100\n",
      "219/219 [==============================] - 0s 915us/step - loss: 0.3370 - accuracy: 0.8594\n",
      "Epoch 88/100\n",
      "219/219 [==============================] - 0s 956us/step - loss: 0.3369 - accuracy: 0.8589\n",
      "Epoch 89/100\n",
      "219/219 [==============================] - 0s 781us/step - loss: 0.3369 - accuracy: 0.8583\n",
      "Epoch 90/100\n",
      "219/219 [==============================] - 0s 691us/step - loss: 0.3365 - accuracy: 0.8584\n",
      "Epoch 91/100\n",
      "219/219 [==============================] - 0s 747us/step - loss: 0.3367 - accuracy: 0.8593\n",
      "Epoch 92/100\n",
      "219/219 [==============================] - 0s 1ms/step - loss: 0.3368 - accuracy: 0.8601\n",
      "Epoch 93/100\n",
      "219/219 [==============================] - 0s 1ms/step - loss: 0.3364 - accuracy: 0.8596\n",
      "Epoch 94/100\n",
      "219/219 [==============================] - 0s 1ms/step - loss: 0.3367 - accuracy: 0.8591\n",
      "Epoch 95/100\n",
      "219/219 [==============================] - 0s 1ms/step - loss: 0.3366 - accuracy: 0.8603\n",
      "Epoch 96/100\n",
      "219/219 [==============================] - 0s 1ms/step - loss: 0.3363 - accuracy: 0.8600\n",
      "Epoch 97/100\n",
      "219/219 [==============================] - 0s 1ms/step - loss: 0.3366 - accuracy: 0.8597\n",
      "Epoch 98/100\n",
      "219/219 [==============================] - 0s 934us/step - loss: 0.3364 - accuracy: 0.8613\n",
      "Epoch 99/100\n",
      "219/219 [==============================] - 0s 893us/step - loss: 0.3361 - accuracy: 0.8597\n",
      "Epoch 100/100\n",
      "219/219 [==============================] - 0s 1ms/step - loss: 0.3361 - accuracy: 0.8583\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x1ba28b20088>"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ann.fit(X_train, y_train, batch_size = 32, epochs = 100)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "tJj5k2MxZga3"
   },
   "source": [
    "## Part 4 - Making the predictions and evaluating the model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "84QFoqGYeXHL"
   },
   "source": [
    "### Predicting the result of a single observation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "CGRo3eacgDdC"
   },
   "source": [
    "Use our ANN model to predict if the customer with the following informations will leave the bank: \n",
    "\n",
    "Geography: France\n",
    "\n",
    "Credit Score: 600\n",
    "\n",
    "Gender: Male\n",
    "\n",
    "Age: 40 years old\n",
    "\n",
    "Tenure: 3 years\n",
    "\n",
    "Balance: \\$ 60000\n",
    "\n",
    "Number of Products: 2\n",
    "\n",
    "Does this customer have a credit card ? Yes\n",
    "\n",
    "Is this customer an Active Member: Yes\n",
    "\n",
    "Estimated Salary: \\$ 50000\n",
    "\n",
    "So, should we say goodbye to that customer ?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "ZhU1LTgPg-kH"
   },
   "source": [
    "**Solution**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "2d8IoCCkeWGL",
    "outputId": "957f3970-e197-4c3b-a150-7f69dc567f5d"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[False]]\n"
     ]
    }
   ],
   "source": [
    "#note that we have taken the threshold for our churners at 0.5 (50%)\n",
    "print(ann.predict(sc.transform([[1, 0, 0, 600, 1, 40, 3, 60000, 2, 1, 1, 50000]])) > 0.5)\n",
    "\n",
    "#Another thing to note here is that transform is being applied here to the test entry and not fit_transform."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "wGjx94g2n7OV"
   },
   "source": [
    "Therefore, our ANN model predicts that this customer stays in the bank!\n",
    "\n",
    "**Important note 1:** Notice that the values of the features were all input in a double pair of square brackets. That's because the \"predict\" method always expects a 2D array as the format of its inputs. And putting our values into a double pair of square brackets makes the input exactly a 2D array.\n",
    "\n",
    "**Important note 2:** Notice also that the \"France\" country was not input as a string in the last column but as \"1, 0, 0\" in the first three columns. That's because of course the predict method expects the one-hot-encoded values of the state, and as we see in the first row of the matrix of features X, \"France\" was encoded as \"1, 0, 0\". And be careful to include these values in the first three columns, because the dummy variables are always created in the first columns."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "u7yx47jPZt11"
   },
   "source": [
    "### Predicting the Test set results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 137
    },
    "colab_type": "code",
    "id": "nIyEeQdRZwgs",
    "outputId": "82330ba8-9bdc-4fd1-d3cf-b6d78ee7c2a3"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0 0]\n",
      " [0 0]\n",
      " [0 0]\n",
      " ...\n",
      " [0 0]\n",
      " [0 0]\n",
      " [0 0]]\n"
     ]
    }
   ],
   "source": [
    "y_pred = ann.predict(X_test)\n",
    "y_pred = (y_pred > 0.5)\n",
    "print(np.concatenate((y_pred.reshape(len(y_pred),1), y_test.reshape(len(y_test),1)),1))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "o0oyfLWoaEGw"
   },
   "source": [
    "### Making the Confusion Matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 68
    },
    "colab_type": "code",
    "id": "ci6K_r6LaF6P",
    "outputId": "4d854e9e-22d5-432f-f6e5-a102fe3ae0bd"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[2329   87]\n",
      " [ 312  272]]\n",
      "/n\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.88      0.96      0.92      2416\n",
      "           1       0.76      0.47      0.58       584\n",
      "\n",
      "    accuracy                           0.87      3000\n",
      "   macro avg       0.82      0.71      0.75      3000\n",
      "weighted avg       0.86      0.87      0.85      3000\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import confusion_matrix, accuracy_score,classification_report\n",
    "cm = confusion_matrix(y_test, y_pred)\n",
    "print(cm)\n",
    "accuracy_score(y_test, y_pred)  #actual values in the row and predicted values in the columns\n",
    "print('/n')\n",
    "print(classification_report(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**The complete picture here shows here that the recall(sensitivity) is pretty low here owing to the low number of values for the people who have churned. This makes the model follow more closely the entries for the non-churners and not so much with the ones that have. This kind of problem needs to be solved using oversampler or undersamplers.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [],
   "name": "artificial_neural_network.ipynb",
   "provenance": [],
   "toc_visible": true
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
